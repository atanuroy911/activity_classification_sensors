{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV dataset into a DataFrame\n",
    "df = pd.read_csv('dataset/aruba-bysecs-full.csv')\n",
    "\n",
    "# Convert the 'datetime' column to a pandas datetime object\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Extract the time part and replace the 'datetime' column\n",
    "df['datetime'] = df['datetime'].dt.time\n",
    "\n",
    "# Rename the 'datetime' column to 'time'\n",
    "df = df.rename(columns={'datetime': 'time'})\n",
    "df.drop(columns=['label_index'], inplace=True)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv('new_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             time  D001  D002  D004  M001  M002  M003  M004  M005  M006  ...  \\\n",
       "0       0.002663     0     0     0     0     0     1     0     0     0  ...   \n",
       "1       0.002747     0     0     0     0     0     0     0     0     0  ...   \n",
       "2       0.105941     0     0     0     0     0     1     0     0     0  ...   \n",
       "3       0.106005     0     0     0     0     0     0     0     0     0  ...   \n",
       "4       0.154419     0     0     0     0     0     1     0     0     0  ...   \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "459042  0.723864     1     0     0     0     0     0     0     0     0  ...   \n",
       "459043  0.723914     1     0     0     0     0     0     0     0     0  ...   \n",
       "459044  0.723953     1     0     0     0     0     0     0     0     0  ...   \n",
       "459045  0.724167     1     0     0     0     0     0     0     0     0  ...   \n",
       "459046  0.724190     1     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "        M023  M024  M025  M026  M027  M028  M029  M030  M031  label  \n",
       "0          0     0     0     0     0     0     0     0     0      8  \n",
       "1          0     0     0     0     0     0     0     0     0      8  \n",
       "2          0     0     0     0     0     0     0     0     0      8  \n",
       "3          0     0     0     0     0     0     0     0     0      8  \n",
       "4          0     0     0     0     0     0     0     0     0      8  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  \n",
       "459042     0     0     0     0     0     0     1     1     0      1  \n",
       "459043     0     0     0     0     0     0     1     1     0      1  \n",
       "459044     0     0     0     0     0     0     1     1     0      1  \n",
       "459045     0     0     0     0     0     0     1     1     0      1  \n",
       "459046     0     0     0     0     0     0     1     1     0      1  \n",
       "\n",
       "[459047 rows x 36 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('new_dataset.csv')\n",
    "\n",
    "# Convert time column to datetime format with appropriate format strings\n",
    "data['time'] = pd.to_datetime(data['time'], format='%H:%M:%S.%f', errors='coerce')\n",
    "data['time'] = data['time'].combine_first(pd.to_datetime(data['time'], format='%H:%M:%S', errors='coerce'))\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "# Create 'time_numerical' feature as seconds since start\n",
    "data['time'] = (data['time'] - data['time'].min()).dt.total_seconds()\n",
    "data['time'] = scaler.fit_transform(data[['time']])\n",
    "\n",
    "sensor_columns = data.columns[1:-1]  # Exclude 'time' and 'label'\n",
    "for column in sensor_columns:\n",
    "    data[column] = data[column].apply(lambda x: 0 if x == 'OFF' else 1)\n",
    "\n",
    "data.to_csv('pp.csv', index=False)\n",
    "\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 459038/459038 [08:18<00:00, 920.03it/s]\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 10\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "# Wrap the loop with tqdm for a progress bar\n",
    "for i in tqdm(range(len(data) - sequence_length + 1)):\n",
    "    sequence = data.iloc[i:i + sequence_length]\n",
    "    label = data.iloc[i + sequence_length - 1]['label']\n",
    "    sequences.append(sequence.drop(columns=['label']).values)\n",
    "    labels.append(label)\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 01:50:41.860169: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-12 01:50:41.895395: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-12 01:50:42.537615: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Build and train LSTM model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 01:50:46.857431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22419 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:19:00.0, compute capability: 8.6\n",
      "2023-08-12 01:50:46.857908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22433 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:65:00.0, compute capability: 8.6\n",
      "Epochs:   0%|          | 0/10 [00:00<?, ?epoch/s]2023-08-12 01:50:48.048108: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-12 01:50:48.179373: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efdae34e440 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-12 01:50:48.179398: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2023-08-12 01:50:48.179403: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2023-08-12 01:50:48.183412: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-12 01:50:48.195246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-08-12 01:50:48.248778: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2023-08-12 01:50:48.251258: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2023-08-12 01:50:48.251272: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2023-08-12 01:50:48.270876: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-08-12 01:50:48.381297: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2023-08-12 01:50:48.508329: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2023-08-12 01:50:48.630391: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2023-08-12 01:50:48.708011: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "Batches: 5738batch [01:57, 48.76batch/s, accuracy=0, loss=nan]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869/2869 [==============================] - 10s 4ms/step - loss: nan - accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|█         | 1/10 [02:08<19:14, 128.23s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Test Loss: nan, Test Accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 5738batch [01:55, 49.49batch/s, accuracy=0, loss=nan]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869/2869 [==============================] - 10s 4ms/step - loss: nan - accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 2/10 [04:14<16:57, 127.16s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Test Loss: nan, Test Accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 5738batch [01:56, 49.38batch/s, accuracy=0, loss=nan]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869/2869 [==============================] - 10s 4ms/step - loss: nan - accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  30%|███       | 3/10 [06:21<14:48, 126.91s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Test Loss: nan, Test Accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 5738batch [01:55, 49.76batch/s, accuracy=0, loss=nan]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869/2869 [==============================] - 10s 4ms/step - loss: nan - accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 4/10 [08:26<12:38, 126.42s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Test Loss: nan, Test Accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 5738batch [01:55, 49.65batch/s, accuracy=0, loss=nan]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869/2869 [==============================] - 10s 4ms/step - loss: nan - accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 5/10 [10:32<10:31, 126.26s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Test Loss: nan, Test Accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 5738batch [01:54, 50.14batch/s, accuracy=0, loss=nan]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869/2869 [==============================] - 10s 4ms/step - loss: nan - accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 6/10 [12:37<08:23, 125.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Test Loss: nan, Test Accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 5738batch [01:54, 50.01batch/s, accuracy=0, loss=nan]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869/2869 [==============================] - 10s 4ms/step - loss: nan - accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  70%|███████   | 7/10 [14:42<06:16, 125.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Test Loss: nan, Test Accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 5738batch [01:54, 49.91batch/s, accuracy=0, loss=nan]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869/2869 [==============================] - 10s 4ms/step - loss: nan - accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 8/10 [16:48<04:11, 125.59s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Test Loss: nan, Test Accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 5738batch [01:54, 50.18batch/s, accuracy=0, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869/2869 [==============================] - 10s 4ms/step - loss: nan - accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  90%|█████████ | 9/10 [18:53<02:05, 125.32s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Test Loss: nan, Test Accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 5738batch [01:53, 50.41batch/s, accuracy=0, loss=nan]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869/2869 [==============================] - 10s 4ms/step - loss: nan - accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 10/10 [20:57<00:00, 125.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Test Loss: nan, Test Accuracy: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869/2869 [==============================] - 10s 4ms/step - loss: nan - accuracy: 0.0035\n",
      "Final Test Loss: nan, Final Test Accuracy: 0.0035\n"
     ]
    }
   ],
   "source": [
    "num_features = X_train.shape[2]\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, input_shape=(sequence_length, num_features), activation='relu'))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Wrap the training loop with tqdm for a progress bar\n",
    "with tqdm(total=epochs, desc=\"Epochs\", unit=\"epoch\") as epoch_progress:\n",
    "    for epoch in range(epochs):\n",
    "        with tqdm(total=len(X_train) // batch_size, desc=\"Batches\", unit=\"batch\") as batch_progress:\n",
    "            for batch_start in range(0, len(X_train), batch_size):\n",
    "                batch_end = batch_start + batch_size\n",
    "                X_batch = X_train[batch_start:batch_end]\n",
    "                y_batch = y_train[batch_start:batch_end]\n",
    "                \n",
    "                history = model.train_on_batch(X_batch, y_batch)\n",
    "                batch_progress.set_postfix(loss=history[0], accuracy=history[1])\n",
    "                batch_progress.update(1)\n",
    "        \n",
    "        # Evaluate the model after each epoch\n",
    "        test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "        \n",
    "        epoch_progress.update(1)\n",
    "\n",
    "# Final evaluation\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
