{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV dataset into a DataFrame\n",
    "df = pd.read_csv('dataset/aruba-bysecs-full.csv')\n",
    "\n",
    "# Convert the 'datetime' column to a pandas datetime object\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Extract the time part and replace the 'datetime' column\n",
    "df['datetime'] = df['datetime'].dt.time\n",
    "\n",
    "# Rename the 'datetime' column to 'time'\n",
    "df = df.rename(columns={'datetime': 'time'})\n",
    "df.drop(columns=['label_index'], inplace=True)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv('new_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             time  D001  D002  D004  M001  M002  M003  M004  M005  M006  ...  \\\n",
       "0         230.11     0     0     0     0     0     1     0     0     0  ...   \n",
       "1         237.30     0     0     0     0     0     0     0     0     0  ...   \n",
       "2        9153.25     0     0     0     0     0     1     0     0     0  ...   \n",
       "3        9158.80     0     0     0     0     0     0     0     0     0  ...   \n",
       "4       13341.72     0     0     0     0     0     1     0     0     0  ...   \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "459042  62541.60     1     0     0     0     0     0     0     0     0  ...   \n",
       "459043  62545.89     1     0     0     0     0     0     0     0     0  ...   \n",
       "459044  62549.25     1     0     0     0     0     0     0     0     0  ...   \n",
       "459045  62567.81     1     0     0     0     0     0     0     0     0  ...   \n",
       "459046  62569.80     1     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "        M023  M024  M025  M026  M027  M028  M029  M030  M031  label  \n",
       "0          0     0     0     0     0     0     0     0     0      8  \n",
       "1          0     0     0     0     0     0     0     0     0      8  \n",
       "2          0     0     0     0     0     0     0     0     0      8  \n",
       "3          0     0     0     0     0     0     0     0     0      8  \n",
       "4          0     0     0     0     0     0     0     0     0      8  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  \n",
       "459042     0     0     0     0     0     0     1     1     0      1  \n",
       "459043     0     0     0     0     0     0     1     1     0      1  \n",
       "459044     0     0     0     0     0     0     1     1     0      1  \n",
       "459045     0     0     0     0     0     0     1     1     0      1  \n",
       "459046     0     0     0     0     0     0     1     1     0      1  \n",
       "\n",
       "[459047 rows x 36 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('new_dataset.csv')\n",
    "\n",
    "# Convert time column to datetime format with appropriate format strings\n",
    "data['time'] = pd.to_datetime(data['time'], format='%H:%M:%S.%f', errors='coerce')\n",
    "data['time'] = data['time'].combine_first(pd.to_datetime(data['time'], format='%H:%M:%S', errors='coerce'))\n",
    "\n",
    "# Calculate the average time difference between consecutive timestamps\n",
    "time_diff = (data['time'].diff() / np.timedelta64(1, 's')).mean()\n",
    "\n",
    "# Fill missing 'time' values by adding the average time difference\n",
    "data['time'] = data['time'].fillna(method='ffill') + pd.to_timedelta(time_diff, unit='s')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['label'])\n",
    "joblib.dump(label_encoder, 'label_encoder.mod')\n",
    "\n",
    "# Convert 'time' column to floating point seconds since start\n",
    "data['time'] = (data['time'] - data['time'].min()).dt.total_seconds()\n",
    "\n",
    "sensor_columns = data.columns[1:-1]  # Exclude 'time' and 'label'\n",
    "for column in sensor_columns:\n",
    "    data[column] = data[column].apply(lambda x: 0 if x == 'OFF' else 1)\n",
    "\n",
    "# data.to_csv('pp.csv', index=False)\n",
    "\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features (X) and labels (y)\n",
    "X = data.iloc[:, :-1]  # Excluding 'label'\n",
    "# print(X)\n",
    "y = data['label']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create and train a Random Forest classifier\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100)  # You can adjust parameters as needed\n",
    "\n",
    "model = random_forest_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "   Bed_to_Toilet       0.87      0.78      0.82       245\n",
      "          Eating       0.91      0.89      0.90      2639\n",
      "      Enter_Home       0.70      0.61      0.65       398\n",
      "    Housekeeping       0.89      0.88      0.89      2035\n",
      "      Leave_Home       0.61      0.59      0.60       320\n",
      "Meal_Preparation       0.97      0.98      0.98     44732\n",
      "           Relax       0.98      0.98      0.98     30358\n",
      "       Respirate       1.00      1.00      1.00        73\n",
      "        Sleeping       0.98      0.98      0.98      5996\n",
      "     Wash_Dishes       0.96      0.94      0.95      2136\n",
      "            Work       0.98      0.98      0.98      2878\n",
      "\n",
      "        accuracy                           0.97     91810\n",
      "       macro avg       0.90      0.87      0.88     91810\n",
      "    weighted avg       0.97      0.97      0.97     91810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "joblib.dump(model, 'random_forest_model.mod') \n",
    "\n",
    "loaded_model = joblib.load('random_forest_model.mod')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_test, y_pred, target_names=class_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
